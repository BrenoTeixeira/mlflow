{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.10.12/envs/mlflowenv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/root/.pyenv/versions/3.10.12/envs/mlflowenv/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "from utill.utils import load_config\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser, EqualWidthDiscretiser\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from data.data_load import DataLoad\n",
    "from train.train import TrainModels\n",
    "from data.data_validation import DataValidation\n",
    "from data.data_transform import DataTransformation\n",
    "from data.data_preprocess import DataPreprocess\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from evaluation.classifier_eval import ModelEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-22 15:26:33\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting data load: train_dataset_name\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoad()\n",
    "df = dl.load_data('train_dataset_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>TaxaDeUtilizacaoDeLinhasNaoGarantidas</th>\n",
       "      <th>Idade</th>\n",
       "      <th>NumeroDeVezes30-59DiasAtrasoNaoPior</th>\n",
       "      <th>TaxaDeEndividamento</th>\n",
       "      <th>RendaMensal</th>\n",
       "      <th>NumeroDeLinhasDeCreditoEEmprestimosAbertos</th>\n",
       "      <th>NumeroDeVezes90DiasAtraso</th>\n",
       "      <th>NumeroDeEmprestimosOuLinhasImobiliarias</th>\n",
       "      <th>NumeroDeVezes60-89DiasAtrasoNaoPior</th>\n",
       "      <th>NumeroDeDependentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  TaxaDeUtilizacaoDeLinhasNaoGarantidas  Idade  \\\n",
       "0       1                               0.766127     45   \n",
       "1       0                               0.957151     40   \n",
       "2       0                               0.658180     38   \n",
       "3       0                               0.233810     30   \n",
       "4       0                               0.907239     49   \n",
       "\n",
       "   NumeroDeVezes30-59DiasAtrasoNaoPior  TaxaDeEndividamento  RendaMensal  \\\n",
       "0                                    2             0.802982       9120.0   \n",
       "1                                    0             0.121876       2600.0   \n",
       "2                                    1             0.085113       3042.0   \n",
       "3                                    0             0.036050       3300.0   \n",
       "4                                    1             0.024926      63588.0   \n",
       "\n",
       "   NumeroDeLinhasDeCreditoEEmprestimosAbertos  NumeroDeVezes90DiasAtraso  \\\n",
       "0                                          13                          0   \n",
       "1                                           4                          0   \n",
       "2                                           2                          1   \n",
       "3                                           5                          0   \n",
       "4                                           7                          0   \n",
       "\n",
       "   NumeroDeEmprestimosOuLinhasImobiliarias  \\\n",
       "0                                        6   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        1   \n",
       "\n",
       "   NumeroDeVezes60-89DiasAtrasoNaoPior  NumeroDeDependentes  \n",
       "0                                    0                  2.0  \n",
       "1                                    0                  1.0  \n",
       "2                                    0                  0.0  \n",
       "3                                    0                  0.0  \n",
       "4                                    0                  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Validation\n",
      "\u001b[2m2023-12-22 15:26:34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mValidation columns passed\u001b[0m\n",
      "\u001b[2m2023-12-22 15:26:34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSuccessful Validation.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dv = DataValidation()\n",
    "is_valid = dv.run(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DataTransformation(df)\n",
    "X_train, X_valid, y_train, y_valid = dt.train_test_splitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TaxaDeUtilizacaoDeLinhasNaoGarantidas</th>\n",
       "      <th>Idade</th>\n",
       "      <th>NumeroDeVezes30-59DiasAtrasoNaoPior</th>\n",
       "      <th>TaxaDeEndividamento</th>\n",
       "      <th>RendaMensal</th>\n",
       "      <th>NumeroDeLinhasDeCreditoEEmprestimosAbertos</th>\n",
       "      <th>NumeroDeVezes90DiasAtraso</th>\n",
       "      <th>NumeroDeEmprestimosOuLinhasImobiliarias</th>\n",
       "      <th>NumeroDeVezes60-89DiasAtrasoNaoPior</th>\n",
       "      <th>NumeroDeDependentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146433</th>\n",
       "      <td>0.183822</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176638</td>\n",
       "      <td>5983.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15597</th>\n",
       "      <td>0.533493</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146019</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111605</th>\n",
       "      <td>1.026997</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065518</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85418</th>\n",
       "      <td>0.017300</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9652</th>\n",
       "      <td>0.682460</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140232</td>\n",
       "      <td>5333.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TaxaDeUtilizacaoDeLinhasNaoGarantidas  Idade  \\\n",
       "146433                               0.183822     30   \n",
       "15597                                0.533493     40   \n",
       "111605                               1.026997     34   \n",
       "85418                                0.017300     83   \n",
       "9652                                 0.682460     61   \n",
       "\n",
       "        NumeroDeVezes30-59DiasAtrasoNaoPior  TaxaDeEndividamento  RendaMensal  \\\n",
       "146433                                    0             0.176638       5983.0   \n",
       "15597                                     0             0.146019       2800.0   \n",
       "111605                                    0             0.065518       4700.0   \n",
       "85418                                     0            19.000000          NaN   \n",
       "9652                                      0             0.140232       5333.0   \n",
       "\n",
       "        NumeroDeLinhasDeCreditoEEmprestimosAbertos  NumeroDeVezes90DiasAtraso  \\\n",
       "146433                                           5                          0   \n",
       "15597                                            2                          0   \n",
       "111605                                           1                          0   \n",
       "85418                                            4                          0   \n",
       "9652                                             3                          0   \n",
       "\n",
       "        NumeroDeEmprestimosOuLinhasImobiliarias  \\\n",
       "146433                                        2   \n",
       "15597                                         0   \n",
       "111605                                        0   \n",
       "85418                                         0   \n",
       "9652                                          0   \n",
       "\n",
       "        NumeroDeVezes60-89DiasAtrasoNaoPior  NumeroDeDependentes  \n",
       "146433                                    0                  1.0  \n",
       "15597                                     0                  0.0  \n",
       "111605                                    0                  0.0  \n",
       "85418                                     0                  0.0  \n",
       "9652                                      0                  2.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TrainModels(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-22 15:26:38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSelecting best model on mflow\u001b[0m\n",
      "\u001b[2m2023-12-22 15:26:38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitializing Model Training: ../models/modelo.joblib\u001b[0m\n",
      "\u001b[2m2023-12-22 15:26:38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitilized Model Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.10.12/envs/mlflowenv/lib/python3.10/site-packages/mlflow/models/signature.py:351: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  input_schema = _infer_schema(input_example)\n",
      "/root/.pyenv/versions/3.10.12/envs/mlflowenv/lib/python3.10/site-packages/mlflow/models/signature.py:362: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  output_schema = _infer_schema(prediction)\n",
      "Successfully registered model 'final_model'.\n",
      "2023/12/22 15:26:41 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: final_model, version 1\n",
      "Created version '1' of model 'final_model'.\n"
     ]
    }
   ],
   "source": [
    "tm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Experimentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1702725813091, experiment_id='1', last_update_time=1702725813091, lifecycle_stage='active', name='prob_loan', tags={}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "mlflow.set_experiment('prob_loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-22 15:19:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitialized Preprocessing\u001b[0m\n",
      "\u001b[2m2023-12-22 15:19:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 15:19:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 15:19:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation initialized\u001b[0m\n",
      "\u001b[2m2023-12-22 15:19:43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitilized Model Validation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='baseline'):\n",
    "    mlflow.set_tag('model_name', 'lr_baseline')\n",
    "\n",
    "\n",
    "    # 1. Etapa de preprocess\n",
    "    pipe = Pipeline([\n",
    "                 ('imputer', MeanMedianImputer(variables=load_config().get('vars_imputer'))), \n",
    "                 ('scaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "                 ])\n",
    "    \n",
    "    preprocessor = DataPreprocess(pipe)\n",
    "    preprocessor.train(X_train)\n",
    "    X_train_prep = preprocessor.transform(X_train)\n",
    "    X_valid_prep = preprocessor.transform(X_valid)\n",
    "    joblib.dump(preprocessor, '../models/preprocess.joblib')\n",
    "\n",
    "\n",
    "    ##1.1 logger atifact\n",
    "    mlflow.log_artifact('../models/preprocess.joblib')\n",
    "\n",
    "    # 1.2 Logger params\n",
    "    mlflow.log_params(params={'imputer': pipe['imputer'],\n",
    "                              'scaler': pipe['scaler']})\n",
    "    \n",
    "    # 2.0 Model\n",
    "    model = LogisticRegression()\n",
    "    model_eval = ModelEvaluation(model,\n",
    "                                 X_train_prep,\n",
    "                                 y_train,\n",
    "                                 n_splits=5)\n",
    "    roc_auc_scores = model_eval.cross_val_evaluate()\n",
    "\n",
    "    ## Result LOG\n",
    "    mlflow.log_metric('train_roc_auc', roc_auc_scores.mean())\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_prep, y_train)\n",
    "\n",
    "    # Save metrics\n",
    "    y_val_preds = model_eval.model.predict_proba(X_valid_prep)[:, 1]\n",
    "    val_roc_auc = model_eval.evaluate_predictions(y_valid, y_val_preds)\n",
    "\n",
    "    mlflow.log_metric('valid_roc_auc', val_roc_auc)\n",
    "\n",
    "\n",
    "    # Log Model\n",
    "    mlflow.sklearn.log_model(model, 'lr_model',\n",
    "                             pyfunc_predict_fn='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.10.12/envs/mlflowenv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/root/.pyenv/versions/3.10.12/envs/mlflowenv/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models import MetricThreshold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "                    ('imputer', MeanMedianImputer(variables=load_config().get('vars_imputer'))),\n",
    "                    ('discretizer', EqualFrequencyDiscretiser(variables=load_config().get('vars_imputer'))), \n",
    "                    ('scaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\n",
    "\n",
    "\n",
    "    with mlflow.start_run(run_name='with_discrtizer_hyperopt'):\n",
    "        mlflow.set_tag('model_name', 'lr_dhyperopt')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "\n",
    "        # 1. Etapa de preprocess\n",
    "        preprocessor = DataPreprocess(pipe)\n",
    "        preprocessor.train(X_train)\n",
    "        X_train_prep = preprocessor.transform(X_train)\n",
    "        X_valid_prep = preprocessor.transform(X_valid)\n",
    "        joblib.dump(preprocessor, '../models/preprocess.joblib')\n",
    "\n",
    "\n",
    "        ##1.1 logger atifact\n",
    "        mlflow.log_artifact('../models/preprocess.joblib')\n",
    "\n",
    "        # 1.2 Logger params\n",
    "        mlflow.log_params(params={'imputer': pipe['imputer'],\n",
    "                                'discretizer': pipe['discretizer'],\n",
    "                                'scaler': pipe['scaler']})\n",
    "        \n",
    "        # 2.0 Model\n",
    "        model = LogisticRegression(**params)\n",
    "        model_eval = ModelEvaluation(model,\n",
    "                                    X_train_prep,\n",
    "                                    y_train,\n",
    "                                    n_splits=5)\n",
    "        roc_auc_scores = model_eval.cross_val_evaluate()\n",
    "\n",
    "        ## Result LOG\n",
    "        mlflow.log_metric('train_roc_auc', roc_auc_scores.mean())\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train_prep, y_train)\n",
    "\n",
    "        # Save metrics\n",
    "        y_val_preds = model_eval.model.predict_proba(X_valid_prep)[:, 1]\n",
    "        val_roc_auc = model_eval.evaluate_predictions(y_valid, y_val_preds)\n",
    "\n",
    "        mlflow.log_metric('valid_roc_auc', val_roc_auc)\n",
    "\n",
    "\n",
    "        # Log Model\n",
    "        candidate_model_uri = mlflow.sklearn.log_model(model, 'lr_model',\n",
    "                                #pyfunc_predict_fn='predict_proba'\n",
    "                                ).model_uri\n",
    "        \n",
    "        ################\n",
    "        signature = infer_signature(X_valid_prep, y_valid)\n",
    "        eval_data = X_valid_prep\n",
    "        eval_data['label'] = y_valid\n",
    "        thresholds = {\n",
    "            'accuracy_score': MetricThreshold(threshold=0.7,\n",
    "                                            min_absolute_change=0.05,\n",
    "                                            min_relative_change=0.05,\n",
    "                                            greater_is_better=True)\n",
    "        }\n",
    "\n",
    "        baseline_model = DummyClassifier(strategy='uniform').fit(X_train_prep, y_train)\n",
    "\n",
    "        baseline_model_uri = mlflow.sklearn.log_model(baseline_model,\n",
    "                                                    'baseline_model',\n",
    "                                                    signature=signature).model_uri\n",
    "        # Avaliar modelo\n",
    "        mlflow.evaluate(candidate_model_uri,\n",
    "                        eval_data,\n",
    "                        targets='label',\n",
    "                        model_type='classifier',\n",
    "                        validation_thresholds=thresholds,\n",
    "                        baseline_model=baseline_model_uri)\n",
    "        \n",
    "        # Explicabilidade com shap\n",
    "        #mlflow.shap.log_explanation(model.predict,\n",
    "        #                            X_valid_prep.drop('label', axis=1))\n",
    "        mlflow.end_run()\n",
    "\n",
    "        return {'loss': -roc_auc_scores.mean(),  'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {'warm_start': hp.choice('warn_start', [True, False]),\n",
    "                'fit_intercept': hp.choice('fit_intercept', [True, False]),\n",
    "                'tol': hp.uniform('tol', 0.00001, 0.0001),\n",
    "                'C': hp.uniform('C', 0.05, 2),\n",
    "                'solver': hp.choice('solver', ['newton-cg', 'lbfgs', 'liblinear']),\n",
    "                'max_iter': hp.choice('max_iter', range(100, 1000)),\n",
    "                'multi_class': 'auto',\n",
    "                'class_weight': hp.choice('class_weight', [None, 'balanced'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-22 13:57:50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitialized Preprocessing\u001b[0m\n",
      "\u001b[2m2023-12-22 13:57:50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 13:57:50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 13:57:50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation initialized\u001b[0m\n",
      "\u001b[2m2023-12-22 13:57:52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitilized Model Validation\u001b[0m\n",
      "  0%|          | 0/5 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 297.30it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 214.52it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 242.23it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 260.69it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 278.67it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 243.38it/s]\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 39.87it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 67.04it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 90.90it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 108.81it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 124.97it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 120.42it/s]\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "2023/12/22 13:57:55 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "\n",
      "2023/12/22 13:57:55 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "\n",
      "2023/12/22 13:57:55 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/22 13:57:55 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/22 13:57:56 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/22 13:57:57 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "\n",
      "2023/12/22 13:57:57 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "\n",
      "2023/12/22 13:57:59 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "\n",
      "2023/12/22 13:57:59 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/22 13:57:59 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/22 13:57:59 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/22 13:57:59 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "\n",
      "2023/12/22 13:57:59 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-22 13:57:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitialized Preprocessing\u001b[0m\n",
      "\u001b[2m2023-12-22 13:57:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 13:57:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 13:57:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation initialized\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitilized Model Validation\u001b[0m\n",
      " 20%|██        | 1/5 [00:10<00:35,  8.97s/trial, best loss: -0.69666429288049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 58.31it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 68.62it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 88.60it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 109.12it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 128.59it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 123.24it/s]\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 47.07it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 68.30it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 90.26it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 110.20it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 130.69it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 125.32it/s]\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "2023/12/22 13:58:04 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "\n",
      "2023/12/22 13:58:04 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "\n",
      "2023/12/22 13:58:04 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/22 13:58:04 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/22 13:58:04 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/22 13:58:05 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "\n",
      "2023/12/22 13:58:05 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "\n",
      "2023/12/22 13:58:07 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "\n",
      "2023/12/22 13:58:07 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/22 13:58:07 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/22 13:58:07 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/22 13:58:07 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "\n",
      "2023/12/22 13:58:07 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-22 13:58:07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitialized Preprocessing\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation initialized\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitilized Model Validation\u001b[0m\n",
      " 40%|████      | 2/5 [00:19<00:24,  8.32s/trial, best loss: -0.7909351628596438]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 86.18it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 77.54it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 88.94it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 107.29it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 123.12it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 118.48it/s]\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 63.33it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 85.06it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 89.68it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 106.95it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 125.77it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 121.05it/s]\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "2023/12/22 13:58:13 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "\n",
      "2023/12/22 13:58:13 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "\n",
      "2023/12/22 13:58:13 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/22 13:58:13 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/22 13:58:13 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/22 13:58:14 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "\n",
      "2023/12/22 13:58:14 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "\n",
      "2023/12/22 13:58:16 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "\n",
      "2023/12/22 13:58:16 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/22 13:58:16 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/22 13:58:16 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/22 13:58:16 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "\n",
      "2023/12/22 13:58:16 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-22 13:58:16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitialized Preprocessing\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation initialized\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitilized Model Validation\u001b[0m\n",
      " 60%|██████    | 3/5 [00:27<00:17,  8.71s/trial, best loss: -0.7909351628596438]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 60.87it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 94.27it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 104.54it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 111.81it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 125.16it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 119.74it/s]\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 62.32it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 94.27it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 87.46it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 104.68it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 123.31it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 117.73it/s]\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "2023/12/22 13:58:21 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "\n",
      "2023/12/22 13:58:21 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "\n",
      "2023/12/22 13:58:21 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/22 13:58:21 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/22 13:58:21 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/22 13:58:23 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "\n",
      "2023/12/22 13:58:23 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "\n",
      "2023/12/22 13:58:24 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "\n",
      "2023/12/22 13:58:24 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/22 13:58:24 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/22 13:58:24 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/22 13:58:24 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "\n",
      "2023/12/22 13:58:24 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-22 13:58:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitialized Preprocessing\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation initialized\u001b[0m\n",
      "\u001b[2m2023-12-22 13:58:27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitilized Model Validation\u001b[0m\n",
      " 80%|████████  | 4/5 [00:36<00:08,  8.55s/trial, best loss: -0.8130256948501391]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 62.24it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 73.18it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 87.24it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 100.72it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 117.51it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 112.86it/s]\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 43.46it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 74.52it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 97.59it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 118.00it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 138.40it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 131.37it/s]\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "2023/12/22 13:58:30 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "\n",
      "2023/12/22 13:58:30 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "\n",
      "2023/12/22 13:58:30 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/22 13:58:30 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/22 13:58:30 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/22 13:58:32 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "\n",
      "2023/12/22 13:58:32 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "\n",
      "2023/12/22 13:58:33 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "\n",
      "2023/12/22 13:58:33 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/22 13:58:33 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/22 13:58:34 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/22 13:58:34 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "\n",
      "2023/12/22 13:58:34 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:43<00:00,  8.69s/trial, best loss: -0.8130256948501391]\n"
     ]
    }
   ],
   "source": [
    "best_result = fmin(fn=objective, space=search_space,\n",
    "                   algo=tpe.suggest,\n",
    "                   max_evals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "                 ('imputer', MeanMedianImputer(variables=load_config().get('vars_imputer'))), \n",
    "                 ('discretizer', EqualFrequencyDiscretiser(variables=load_config().get('vars_imputer'))),\n",
    "                 ('scaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocess(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artifact_location': 'mlflow-artifacts:/1',\n",
       " 'creation_time': 1702725813091,\n",
       " 'experiment_id': '1',\n",
       " 'last_update_time': 1702725813091,\n",
       " 'lifecycle_stage': 'active',\n",
       " 'name': 'prob_loan',\n",
       " 'tags': {}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_experiment = dict(mlflow.get_experiment_by_name('prob_loan'))\n",
    "current_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exepriment_id = current_experiment['experiment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>metrics.valid_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f134ec2b086d4ecd98dc7215c591a0d6</td>\n",
       "      <td>0.821449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b33be2e3332c4a489bb2d7831f3127dd</td>\n",
       "      <td>0.821339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca0e18683f0a4d4ca16bbe84218213a2</td>\n",
       "      <td>0.800721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64130810d538443faa1072d1d2edbe95</td>\n",
       "      <td>0.800651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6cf73a631ff04677b43c68bdea0293d8</td>\n",
       "      <td>0.712063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34b34557f1ad451792348db3ef437d8a</td>\n",
       "      <td>0.711076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e12f3ec2894341c48d7ffe88aed24bc4</td>\n",
       "      <td>0.711076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9ca3c89d940441a6b3aba141a9157b71</td>\n",
       "      <td>0.711076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31bb52dd61734498a85cb4f82c664c49</td>\n",
       "      <td>0.707613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id  metrics.valid_roc_auc\n",
       "1  f134ec2b086d4ecd98dc7215c591a0d6               0.821449\n",
       "0  b33be2e3332c4a489bb2d7831f3127dd               0.821339\n",
       "3  ca0e18683f0a4d4ca16bbe84218213a2               0.800721\n",
       "2  64130810d538443faa1072d1d2edbe95               0.800651\n",
       "4  6cf73a631ff04677b43c68bdea0293d8               0.712063\n",
       "5  34b34557f1ad451792348db3ef437d8a               0.711076\n",
       "6  e12f3ec2894341c48d7ffe88aed24bc4               0.711076\n",
       "7  9ca3c89d940441a6b3aba141a9157b71               0.711076\n",
       "8  31bb52dd61734498a85cb4f82c664c49               0.707613"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlflow = mlflow.search_runs(filter_string='metrics.valid_roc_auc < 1').sort_values('metrics.valid_roc_auc', ascending=False)\n",
    "df_mlflow[['run_id', 'metrics.valid_roc_auc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['run_id', 'experiment_id', 'status', 'artifact_uri', 'start_time',\n",
       "       'end_time', 'metrics.accuracy_score', 'metrics.recall_score',\n",
       "       'metrics.false_positives', 'metrics.true_positives', 'metrics.log_loss',\n",
       "       'metrics.f1_score', 'metrics.valid_roc_auc', 'metrics.score',\n",
       "       'metrics.train_roc_auc', 'metrics.precision_score',\n",
       "       'metrics.example_count', 'metrics.roc_auc',\n",
       "       'metrics.precision_recall_auc', 'metrics.false_negatives',\n",
       "       'metrics.true_negatives', 'params.class_weight', 'params.tol',\n",
       "       'params.imputer', 'params.warm_start', 'params.max_iter',\n",
       "       'params.solver', 'params.multi_class', 'params.scaler',\n",
       "       'params.fit_intercept', 'params.discretizer', 'params.C',\n",
       "       'tags.mlflow.source.name', 'tags.mlflow.user',\n",
       "       'tags.mlflow.log-model.history', 'tags.mlflow.runName',\n",
       "       'tags.mlflow.datasets', 'tags.model_name', 'tags.mlflow.source.type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlflow.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.class_weight', 'params.tol',\n",
    "       'params.imputer', 'params.warm_start', 'params.max_iter',\n",
    "       'params.solver', 'params.multi_class', 'params.scaler',\n",
    "       'params.fit_intercept', 'params.discretizer', 'params.C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlflow['metrics.valid_roc_auc'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f134ec2b086d4ecd98dc7215c591a0d6'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id  = df_mlflow.loc[df_mlflow['metrics.valid_roc_auc'].idxmax()].run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f134ec2b086d4ecd98dc7215c591a0d6'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = df_mlflow.iloc[0].run_id\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params.class_weight</th>\n",
       "      <th>params.tol</th>\n",
       "      <th>params.imputer</th>\n",
       "      <th>params.warm_start</th>\n",
       "      <th>params.max_iter</th>\n",
       "      <th>params.solver</th>\n",
       "      <th>params.multi_class</th>\n",
       "      <th>params.scaler</th>\n",
       "      <th>params.fit_intercept</th>\n",
       "      <th>params.discretizer</th>\n",
       "      <th>params.C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>1.0037124436737777e-05</td>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>False</td>\n",
       "      <td>469</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>auto</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>False</td>\n",
       "      <td>EqualFrequencyDiscretiser(variables=['RendaMen...</td>\n",
       "      <td>0.1916031348122706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2.505992461591161e-05</td>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>False</td>\n",
       "      <td>956</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>auto</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>False</td>\n",
       "      <td>EqualFrequencyDiscretiser(variables=['RendaMen...</td>\n",
       "      <td>1.0890394817000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced</td>\n",
       "      <td>6.452644561220985e-05</td>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>True</td>\n",
       "      <td>563</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>auto</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>True</td>\n",
       "      <td>EqualFrequencyDiscretiser(variables=['RendaMen...</td>\n",
       "      <td>1.8561787278932036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balanced</td>\n",
       "      <td>4.488938086498805e-05</td>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>True</td>\n",
       "      <td>277</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>auto</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>True</td>\n",
       "      <td>EqualFrequencyDiscretiser(variables=['RendaMen...</td>\n",
       "      <td>0.3033409704279228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>2.5155909349476943e-05</td>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>False</td>\n",
       "      <td>321</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>auto</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>True</td>\n",
       "      <td>EqualFrequencyDiscretiser(variables=['RendaMen...</td>\n",
       "      <td>0.14436972742273202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>None</td>\n",
       "      <td>EqualFrequencyDiscretiser(variables=['RendaMen...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>None</td>\n",
       "      <td>EqualFrequencyDiscretiser(variables=['RendaMen...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>None</td>\n",
       "      <td>EqualFrequencyDiscretiser(variables=['RendaMen...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  params.class_weight              params.tol  \\\n",
       "1                None  1.0037124436737777e-05   \n",
       "0                None   2.505992461591161e-05   \n",
       "3            balanced   6.452644561220985e-05   \n",
       "2            balanced   4.488938086498805e-05   \n",
       "4                None  2.5155909349476943e-05   \n",
       "5                None                    None   \n",
       "6                None                    None   \n",
       "7                None                    None   \n",
       "8                None                    None   \n",
       "\n",
       "                                      params.imputer params.warm_start  \\\n",
       "1  MeanMedianImputer(variables=['RendaMensal', 'N...             False   \n",
       "0  MeanMedianImputer(variables=['RendaMensal', 'N...             False   \n",
       "3  MeanMedianImputer(variables=['RendaMensal', 'N...              True   \n",
       "2  MeanMedianImputer(variables=['RendaMensal', 'N...              True   \n",
       "4  MeanMedianImputer(variables=['RendaMensal', 'N...             False   \n",
       "5  MeanMedianImputer(variables=['RendaMensal', 'N...              None   \n",
       "6  MeanMedianImputer(variables=['RendaMensal', 'N...              None   \n",
       "7  MeanMedianImputer(variables=['RendaMensal', 'N...              None   \n",
       "8  MeanMedianImputer(variables=['RendaMensal', 'N...              None   \n",
       "\n",
       "  params.max_iter params.solver params.multi_class  \\\n",
       "1             469         lbfgs               auto   \n",
       "0             956     liblinear               auto   \n",
       "3             563         lbfgs               auto   \n",
       "2             277     liblinear               auto   \n",
       "4             321     newton-cg               auto   \n",
       "5            None          None               None   \n",
       "6            None          None               None   \n",
       "7            None          None               None   \n",
       "8            None          None               None   \n",
       "\n",
       "                                       params.scaler params.fit_intercept  \\\n",
       "1  SklearnTransformerWrapper(transformer=Standard...                False   \n",
       "0  SklearnTransformerWrapper(transformer=Standard...                False   \n",
       "3  SklearnTransformerWrapper(transformer=Standard...                 True   \n",
       "2  SklearnTransformerWrapper(transformer=Standard...                 True   \n",
       "4  SklearnTransformerWrapper(transformer=Standard...                 True   \n",
       "5  SklearnTransformerWrapper(transformer=Standard...                 None   \n",
       "6  SklearnTransformerWrapper(transformer=Standard...                 None   \n",
       "7  SklearnTransformerWrapper(transformer=Standard...                 None   \n",
       "8  SklearnTransformerWrapper(transformer=Standard...                 None   \n",
       "\n",
       "                                  params.discretizer             params.C  \n",
       "1  EqualFrequencyDiscretiser(variables=['RendaMen...   0.1916031348122706  \n",
       "0  EqualFrequencyDiscretiser(variables=['RendaMen...   1.0890394817000022  \n",
       "3  EqualFrequencyDiscretiser(variables=['RendaMen...   1.8561787278932036  \n",
       "2  EqualFrequencyDiscretiser(variables=['RendaMen...   0.3033409704279228  \n",
       "4  EqualFrequencyDiscretiser(variables=['RendaMen...  0.14436972742273202  \n",
       "5  EqualFrequencyDiscretiser(variables=['RendaMen...                 None  \n",
       "6  EqualFrequencyDiscretiser(variables=['RendaMen...                 None  \n",
       "7  EqualFrequencyDiscretiser(variables=['RendaMen...                 None  \n",
       "8                                               None                 None  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlflow.filter(like='params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params.class_weight</th>\n",
       "      <th>params.tol</th>\n",
       "      <th>params.imputer</th>\n",
       "      <th>params.warm_start</th>\n",
       "      <th>params.max_iter</th>\n",
       "      <th>params.solver</th>\n",
       "      <th>params.multi_class</th>\n",
       "      <th>params.scaler</th>\n",
       "      <th>params.fit_intercept</th>\n",
       "      <th>params.discretizer</th>\n",
       "      <th>params.C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>1.0037124436737777e-05</td>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>False</td>\n",
       "      <td>469</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>auto</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>False</td>\n",
       "      <td>EqualFrequencyDiscretiser(variables=['RendaMen...</td>\n",
       "      <td>0.1916031348122706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  params.class_weight              params.tol  \\\n",
       "1                None  1.0037124436737777e-05   \n",
       "\n",
       "                                      params.imputer params.warm_start  \\\n",
       "1  MeanMedianImputer(variables=['RendaMensal', 'N...             False   \n",
       "\n",
       "  params.max_iter params.solver params.multi_class  \\\n",
       "1             469         lbfgs               auto   \n",
       "\n",
       "                                       params.scaler params.fit_intercept  \\\n",
       "1  SklearnTransformerWrapper(transformer=Standard...                False   \n",
       "\n",
       "                                  params.discretizer            params.C  \n",
       "1  EqualFrequencyDiscretiser(variables=['RendaMen...  0.1916031348122706  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlflow.query(f'run_id == \"{run_id}\"').filter(like='params')#.filter(like='params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-22 14:23:58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitialized Preprocessing\u001b[0m\n",
      "\u001b[2m2023-12-22 14:23:58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData Transformation with preprocess started...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "preprocessor = DataPreprocess(pipe)\n",
    "preprocessor.train(X_train)\n",
    "X_valid_prep = preprocessor.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 144.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_model = f'runs:/{run_id}/lr_model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(X_valid_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = loaded_model.predict(X_valid_prep)\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflowenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
